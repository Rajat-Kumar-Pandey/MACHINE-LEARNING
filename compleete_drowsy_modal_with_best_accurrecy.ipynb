{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN2nmiQ0q6tYOsnBURSrsVF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rajat-Kumar-Pandey/MACHINE-LEARNING/blob/main/compleete_drowsy_modal_with_best_accurrecy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gTrju2zX4Rb"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.applications import EfficientNetV2S\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, Callback\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import logging\n",
        "import os\n",
        "import json\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger(__name__)\n",
        "logger.info(\"Script execution started.\")\n",
        "\n",
        "# Constants\n",
        "SEED = 123\n",
        "IMAGE_SIZE = 256\n",
        "CHANNELS = 3\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 30\n",
        "N_CLASSES = 2\n",
        "\n",
        "# Enable mixed precision for faster training on GPUs\n",
        "policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
        "tf.keras.mixed_precision.set_global_policy(policy)\n",
        "logger.info(\"Mixed precision policy set to 'mixed_float16'.\")\n",
        "\n",
        "# Check if GPU (CUDA) is available and enable memory growth\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "if physical_devices:\n",
        "    logger.info(f\"GPU available: {physical_devices}\")\n",
        "    for gpu in physical_devices:\n",
        "        tf.config.experimental.set_memory_growth(gpu, True)\n",
        "else:\n",
        "    logger.warning(\"No GPU found, using CPU instead.\")\n",
        "\n",
        "# Dataset path\n",
        "DATASET_PATH = '/content/drive/MyDrive/Drowsiness_Data/Resized_Driver_Drowsiness_Dataset'\n",
        "\n",
        "# Data augmentation\n",
        "logger.info(\"Initializing data augmentation...\")\n",
        "data_gen = ImageDataGenerator(\n",
        "    rescale=1.0/255.0,\n",
        "    validation_split=0.2,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=20,\n",
        "    zoom_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    brightness_range=(0.8, 1.2)\n",
        ")\n",
        "\n",
        "train_generator = data_gen.flow_from_directory(\n",
        "    DATASET_PATH,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='sparse',\n",
        "    subset='training',\n",
        "    shuffle=True,\n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "val_generator = data_gen.flow_from_directory(\n",
        "    DATASET_PATH,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='sparse',\n",
        "    subset='validation',\n",
        "    shuffle=False,\n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "# Build EfficientNetV2S model\n",
        "logger.info(\"Building EfficientNetV2S model...\")\n",
        "def build_efficientnet_model():\n",
        "    base_model = EfficientNetV2S(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), include_top=False, weights=\"imagenet\")\n",
        "    base_model.trainable = False  # Freeze the base model\n",
        "\n",
        "    model = Sequential([\n",
        "        base_model,\n",
        "        GlobalAveragePooling2D(),\n",
        "        BatchNormalization(),\n",
        "        Dense(1024, activation='relu'),\n",
        "        Dropout(0.4),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(N_CLASSES, activation='softmax', dtype='float32'),\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "cnn_model = build_efficientnet_model()\n",
        "cnn_model.summary()\n",
        "\n",
        "# Compile the model\n",
        "logger.info(\"Compiling the model...\")\n",
        "cnn_model.compile(\n",
        "    optimizer=Adam(learning_rate=0.0001),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Custom callback for saving high-accuracy models\n",
        "class SaveHighAccuracyModel(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if logs.get('val_accuracy') > 0.98:\n",
        "            logger.info(f\"Validation accuracy exceeded 98% at epoch {epoch + 1}. Saving model...\")\n",
        "            self.model.save(f'efficientnet_high_accuracy_epoch_{epoch + 1}.h5')\n",
        "\n",
        "# Callbacks\n",
        "callbacks = [\n",
        "    ModelCheckpoint('efficientnet_best_model.keras', monitor='val_accuracy', save_best_only=True, verbose=1),\n",
        "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1),\n",
        "    TensorBoard(log_dir='./logs', histogram_freq=1),\n",
        "    SaveHighAccuracyModel()\n",
        "]\n",
        "\n",
        "# Train the model\n",
        "logger.info(\"Starting training...\")\n",
        "history = cnn_model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Save the final model and training history\n",
        "cnn_model.save('efficientnet_final_model.h5')\n",
        "logger.info(\"Final model saved as 'efficientnet_final_model.h5'.\")\n",
        "\n",
        "with open('training_history.json', 'w') as f:\n",
        "    json.dump(history.history, f)\n",
        "logger.info(\"Training history saved.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mYI8oDZ1aMNy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}